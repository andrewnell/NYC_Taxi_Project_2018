{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import os \n",
    "import sys\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Make Data Directory to store data\n",
    "!mkdir Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DownloadDataMonth(URL):\n",
    "    \"\"\" Need to fill in\"\"\"\n",
    "    for yr in range(2015,2018):\n",
    "        # Define year\n",
    "        year = str(yr)\n",
    "\n",
    "        for mnth in range(1,13):\n",
    "            # Define month\n",
    "            month = ('{:02d}'.format(mnth))\n",
    "\n",
    "            # Create url and filenames\n",
    "            url = str(URL) + year + \"-\" + month + \".csv\"\n",
    "            filename = str(url).split('/')[-1]\n",
    "\n",
    "            # Yellow Taxis\n",
    "            os.system(\"wget \" + url)\n",
    "            os.system(\"mv \" + filename +  \" Data\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Download All the data\n",
    "# Yellow taxis\n",
    "DownloadDataMonth(\"https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_\")\n",
    "# Green Taxis\n",
    "DownloadDataMonth(\"https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_\")\n",
    "# FHV \n",
    "DownloadDataMonth(\"https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Download Taxi Zones Data\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/misc/taxi_zones.zip\n",
    "!mv taxi_zones.zip Data\n",
    "!mkdir Data/Taxi_Zone_Shapefile\n",
    "!unzip Data/taxi_zones.zip -d Data/Taxi_Zone_Shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Taxi Data Sets for Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi Zone Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in taxi zones\n",
    "taxizones = gpd.read_file(\"Data/Taxi_Zone_Shapefile/taxi_zones.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CRS to functional one\n",
    "taxizones = taxizones.to_crs(epsg=2263)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zone</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>borough</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>POLYGON ((933100.9183527121 192536.0857092953,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>(POLYGON ((1033269.243591295 172126.0078245941...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>POLYGON ((1026308.769506665 256767.6975524619,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>POLYGON ((992073.4667968614 203714.0760008526,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>POLYGON ((935843.3104932597 144283.3358627402,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      zone  LocationID        borough  \\\n",
       "0           Newark Airport           1            EWR   \n",
       "1              Jamaica Bay           2         Queens   \n",
       "2  Allerton/Pelham Gardens           3          Bronx   \n",
       "3            Alphabet City           4      Manhattan   \n",
       "4            Arden Heights           5  Staten Island   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((933100.9183527121 192536.0857092953,...  \n",
       "1  (POLYGON ((1033269.243591295 172126.0078245941...  \n",
       "2  POLYGON ((1026308.769506665 256767.6975524619,...  \n",
       "3  POLYGON ((992073.4667968614 203714.0760008526,...  \n",
       "4  POLYGON ((935843.3104932597 144283.3358627402,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop redundant columns\n",
    "taxizones.drop(['OBJECTID','Shape_Leng','Shape_Area'],axis=1,inplace=True)\n",
    "taxizones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yellow Taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Yellow Taxi Processing Data Function\n",
    "def ProcessYTData():\n",
    "    \"\"\" Need to fill in\"\"\"\n",
    "    \n",
    "    \n",
    "    # Create Blank Dataframes\n",
    "    df_Loc = pd.DataFrame(columns=['tpep_pickup_datetime',\n",
    "                                   'pickup_longitude',\n",
    "                                   'pickup_latitude'])\n",
    "\n",
    "    df_ID = pd.DataFrame(columns=['tpep_pickup_datetime',\n",
    "                                  \"PULocationID\"])\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "    for yr in range(2015,2018):\n",
    "        # Define year\n",
    "        year = str(yr)\n",
    "\n",
    "        for mnth in range(1,13):\n",
    "            # Define month\n",
    "            month = ('{:02d}'.format(mnth))\n",
    "            \n",
    "            # Download Data and format\n",
    "            temp = pd.read_csv(\"Data/yellow_tripdata_\" + \n",
    "                               year + \"-\" + month + \".csv\")\n",
    "            \n",
    "            if(sum(temp.ix[:,-2:].isnull().sum()/len(temp)) == 2.0):\n",
    "                #fix indexing problem\n",
    "                columns = temp.columns\n",
    "                temp = temp.reset_index()\n",
    "                temp = temp.drop(columns[-2:], axis=1)\n",
    "                temp.columns = columns\n",
    "\n",
    "            #CHECK IF LON LAT IS INCLUDED\n",
    "            if \"pickup_longitude\" in temp.columns:\n",
    "                temp = temp[['tpep_pickup_datetime',\n",
    "                             'pickup_longitude',\n",
    "                             'pickup_latitude']]\n",
    "\n",
    "                # Append to larger lat/lon dataframe\n",
    "                df_Loc = pd.concat([df_Loc, temp]).reset_index(drop=True)\n",
    "\n",
    "            else:\n",
    "                temp = temp[['tpep_pickup_datetime',\n",
    "                                 \"PULocationID\"]]\n",
    "                df_ID = pd.concat([df_ID, temp]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Provide Status Update\n",
    "            print(\"Completed \" + str(year) + \"-\" + str(month))\n",
    "            \n",
    "###############################################################################            \n",
    "\n",
    "    # Change Name of columns\n",
    "    if len(df_Loc) > 0:\n",
    "        df_Loc.rename(columns={'tpep_pickup_datetime': 'pickup_date'},inplace=True)\n",
    "        df_Loc['Base'] = 'Yellow'\n",
    "\n",
    "\n",
    "        # Filter out invalid data points (outside of NYC)\n",
    "        # Drop Coords out of range \n",
    "        #West -74.257159 East -73.699215\n",
    "        #North 40.915568 South 40.495992\n",
    "        df_Loc = df_Loc[~((df_Loc.pickup_longitude < -74.5) | (df_Loc.pickup_longitude > -73))]\n",
    "        df_Loc = df_Loc[~((df_Loc.pickup_latitude < 40) | (df_Loc.pickup_latitude > 41))]\n",
    "\n",
    "        # Convert Lat Long into point geometry\n",
    "        crs = {'init':'epsg:4326'}\n",
    "        geometry = [Point(xy) for xy in zip(df_Loc.pickup_longitude, \n",
    "                                            df_Loc.pickup_latitude)]\n",
    "        df_Loc = GeoDataFrame(df_Loc, crs=crs, geometry=geometry)\n",
    "\n",
    "        # COnvert Cooords for Spatial join\n",
    "        df_Loc =  df_Loc.to_crs(epsg=2263)\n",
    "        print(\"Coordinates Converted\")\n",
    "\n",
    "        # Conduct Spatial Join to identify tazi zone of pickup\n",
    "        print(\"spatial join starting. This may take a while\")\n",
    "\n",
    "        df_Loc = gpd.sjoin(df_Loc, taxizones,op='within')\n",
    "        print(\"spatial join complete\")\n",
    "\n",
    "        # Drop Columns\n",
    "        df_Loc = df_Loc[['pickup_date','LocationID','zone','borough','Base']]\n",
    "\n",
    "        # Create a date column\n",
    "        df_Loc.pickup_date = pd.to_datetime(df_Loc.pickup_date)\n",
    "        df_Loc['date'] = df_Loc.pickup_date.dt.date\n",
    "        df_Loc['hour'] = df_Loc.pickup_date.dt.hour\n",
    "\n",
    "    # Merge Location IDs to get Borough and anme of zone\n",
    "    if len(df_ID) > 0:\n",
    "        df_ID = pd.merge(df_ID,taxizones,left_on='PULocationID',right_on='LocationID')\n",
    "\n",
    "        # Drop irrelevant columns\n",
    "        df_ID = df_ID[['tpep_pickup_datetime','PULocationID','zone','borough']]\n",
    "\n",
    "        # Rename columns for merging\n",
    "        df_ID.rename(columns={'tpep_pickup_datetime':'pickup_date','PULocationID':'LocationID'},\n",
    "                     inplace=True)\n",
    "\n",
    "        df_ID['Base'] = 'Yellow'\n",
    "\n",
    "        # Create Day and Hour Columns\n",
    "        df_ID.pickup_date = pd.to_datetime(df_ID.pickup_date)\n",
    "        df_ID['date'] = df_ID.pickup_date.dt.date\n",
    "        df_ID['hour'] = df_ID.pickup_date.dt.hour\n",
    "    \n",
    "    df = pd.concat([df_Loc,df_ID]).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 2015-01\n",
      "Completed 2015-02\n",
      "Completed 2015-03\n",
      "Completed 2015-04\n",
      "Completed 2015-05\n",
      "Completed 2015-06\n",
      "Completed 2015-07\n",
      "Completed 2015-08\n",
      "Completed 2015-09\n",
      "Completed 2015-10\n",
      "Completed 2015-11\n",
      "Completed 2015-12\n",
      "Completed 2016-01\n",
      "Completed 2016-02\n",
      "Completed 2016-03\n",
      "Completed 2016-04\n",
      "Completed 2016-05\n",
      "Completed 2016-06\n",
      "Completed 2016-07\n",
      "Completed 2016-08\n",
      "Completed 2016-09\n",
      "Completed 2016-10\n",
      "Completed 2016-11\n",
      "Completed 2016-12\n",
      "Completed 2017-01\n",
      "Completed 2017-02\n",
      "Completed 2017-03\n",
      "Completed 2017-04\n",
      "Completed 2017-05\n",
      "Completed 2017-06\n",
      "Completed 2017-07\n",
      "Completed 2017-08\n",
      "Completed 2017-09\n",
      "Completed 2017-10\n",
      "Completed 2017-11\n",
      "Completed 2017-12\n"
     ]
    }
   ],
   "source": [
    "Yellow = ProcessYTData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YellowGroup = Yellow.groupby(('date','Base','zone'))['pickup_date'].count().reset_index()\n",
    "YellowGroup.rename(columns={'pickup_date':'COUNTS'},inplace=True)\n",
    "YellowGroup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Green Taxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Green Taxi Processing Data Function\n",
    "def GTProcessData():\n",
    "    \"\"\" Need to fill in\"\"\"\n",
    "    # Create Blank Dataframe\n",
    "    df_Loc = pd.DataFrame(columns=['lpep_pickup_datetime',\n",
    "                                   'Pickup_longitude',\n",
    "                                   'Pickup_latitude'])\n",
    "    df_ID = pd.DataFrame(columns=['lpep_pickup_datetime',\n",
    "                                  \"PULocationID\"])\n",
    "    \n",
    "    for yr in range(2015,2018):\n",
    "        # Define year\n",
    "        year = str(yr)\n",
    "\n",
    "        for mnth in range(1,13):\n",
    "            # Define month\n",
    "            month = ('{:02d}'.format(mnth))\n",
    "            \n",
    "            # Download Data and format\n",
    "            temp = pd.read_csv(\"Data/green_tripdata_\" + \n",
    "                               year + \"-\" + month + \".csv\")\n",
    "            \n",
    "            if(sum(temp.ix[:,-2:].isnull().sum()/len(temp)) == 2.0):\n",
    "                #fix indexing problem\n",
    "                columns = temp.columns\n",
    "                temp = temp.reset_index()\n",
    "                temp = temp.drop(columns[-2:], axis=1)\n",
    "                temp.columns = columns\n",
    "            \n",
    "            \n",
    "            if \"Pickup_longitude\" in temp.columns:\n",
    "                temp = temp[['lpep_pickup_datetime',\n",
    "                             'Pickup_longitude',\n",
    "                             'Pickup_latitude']]\n",
    "                df_Loc = pd.concat([df_Loc, temp]).reset_index(drop=True)\n",
    "\n",
    "            else:\n",
    "                temp = temp[['lpep_pickup_datetime',\"PULocationID\"]]\n",
    "                df_ID = pd.concat([df_ID, temp]).reset_index(drop=True)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Provide Status Update\n",
    "            print(\"Completed \" + str(year) + \"-\" + str(month))\n",
    "###############################################################################            \n",
    "    # Change Name of columns\n",
    "    if len(df_Loc > 0):\n",
    "        df_Loc.rename(columns={'lpep_pickup_datetime': 'pickup_date',\n",
    "                           'Pickup_longitude':'pickup_longitude',\n",
    "                           'Pickup_latitude':'pickup_latitude'},inplace=True)\n",
    "        df_Loc['Base'] = 'Green'\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "        # Filter out invalid data points (outside of NYC)\n",
    "        # Drop Coords out of range \n",
    "        #West -74.257159 East -73.699215\n",
    "        #North 40.915568 South 40.495992\n",
    "        df_Loc = df_Loc[~((df_Loc.pickup_longitude < -74.5) | (df_Loc.pickup_longitude > -73))]\n",
    "        df_Loc = df_Loc[~((df_Loc.pickup_latitude < 40) | (df_Loc.pickup_latitude > 41))]\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "        # Convert Lat Long into point geometry\n",
    "        crs = {'init':'epsg:4326'}\n",
    "        geometry = [Point(xy) for xy in zip(df_Loc.pickup_longitude, \n",
    "                                            df_Loc.pickup_latitude)]\n",
    "        df_Loc = GeoDataFrame(df_Loc, crs=crs, geometry=geometry)\n",
    "\n",
    "        # COnvert Cooords for Spatial join\n",
    "        df_Loc =  df_Loc.to_crs(epsg=2263)\n",
    "        print(\"Coordinates Converted\")\n",
    "\n",
    "        # Conduct Spatial Join to identify tazi zone of pickup\n",
    "        print(\"spatial join starting. This may take a while\")\n",
    "        df_Loc = gpd.sjoin(df_Loc, taxizones,op='within')\n",
    "        print(\"spatial join complete\")\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "        # Drop Columns\n",
    "        df_Loc = df_Loc[['pickup_date','LocationID','zone','borough','Base']]\n",
    "\n",
    "        # Create a date column\n",
    "        df_Loc.pickup_date = pd.to_datetime(df_Loc.pickup_date)\n",
    "        df_Loc['date'] = df_Loc.pickup_date.dt.date\n",
    "        df_Loc['hour'] = df_Loc.pickup_date.dt.hour\n",
    "    \n",
    "############################################################################## \n",
    "\n",
    "    if len(df_ID > 0):\n",
    "        df_ID = pd.merge(df_ID,taxizones,left_on='PULocationID',right_on='LocationID')\n",
    "\n",
    "        # Drop irrelevant columns\n",
    "        df_ID = df_ID[['lpep_pickup_datetime','PULocationID','zone','borough']]\n",
    "\n",
    "        # Rename columns for merging\n",
    "        df_ID.rename(columns={'lpep_pickup_datetime':'pickup_date','PULocationID':'LocationID'},\n",
    "                     inplace=True)\n",
    "\n",
    "        df_ID['Base'] = 'Green'\n",
    "\n",
    "        # Create Day and Hour Columns\n",
    "        df_ID.pickup_date = pd.to_datetime(df_ID.pickup_date)\n",
    "        df_ID['date'] = df_ID.pickup_date.dt.date\n",
    "        df_ID['hour'] = df_ID.pickup_date.dt.hour\n",
    "\n",
    "    df = pd.concat([df_Loc,df_ID]).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Green = GTProcessData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GreenGroup = Green.groupby(('date','Base','zone'))['pickup_date'].count().reset_index()\n",
    "GreenGroup.rename(columns={'pickup_date':'COUNTS'},inplace=True)\n",
    "GreenGroup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxi Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Taxi Bases Lists\n",
    "TLCbasesComm = pd.read_excel(\"http://www1.nyc.gov/assets/tlc/downloads/datasets/current_community_car_service_bases.xls\")\n",
    "TLCbasesBlack = pd.read_excel(\"http://www1.nyc.gov/assets/tlc/downloads/datasets/current_black_car_bases.xls\")\n",
    "TLCbasesLux = pd.read_excel(\"http://www1.nyc.gov/assets/tlc/downloads/datasets/current_luxury_limousine_bases.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "\n",
    "# Drop Unnecessary Columns and rename ones that are inccorectly labeled\n",
    "TLCbasesComm = TLCbasesComm[['LICENSEE NUMBER', 'NAME OF LICENSEE', \n",
    "                             'ALTERNATE NAME OF LICENSEE']]\n",
    "TLCbasesBlack = TLCbasesBlack[['LICENSEE NUMBER', 'NAME OF LICENSEE', \n",
    "                               'ALTERNATE NAME OF LICENSEE']]\n",
    "TLCbasesLux = TLCbasesLux[['LICENSEE NUMBER', 'NAME OF LICENSEE', \n",
    "                           'ALTERNATIVE NAME OF LICENSEE']]\n",
    "\n",
    "TLCbasesLux = TLCbasesLux.rename(columns={\"ALTERNATIVE NAME OF LICENSEE\":\n",
    "                                          'ALTERNATE NAME OF LICENSEE'})\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# Merge Taxi Bases list and drop irrelevant columns\n",
    "TLCbases = pd.concat([TLCbasesComm,TLCbasesBlack,TLCbasesLux]).reset_index()\n",
    "TLCbases.drop(['index'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLCbases.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From preliminary analysis and sense check with Uber 538 data we know that we are missing one base for Uber, presumably because the base is no longer used. \n",
    "\n",
    "We need to add this base to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data point\n",
    "tempdf = pd.DataFrame([['B02598',' ','uber' ]], columns=('LICENSEE NUMBER','NAME OF LICENSEE','ALTERNATE NAME OF LICENSEE'))\n",
    "tempdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append onto dat TLC bases\n",
    "TLCbases = TLCbases.append(tempdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove null bases and make all strings lower case\n",
    "TLCbases.dropna(inplace=True)\n",
    "TLCbases['ALTERNATE NAME OF LICENSEE'] = TLCbases['ALTERNATE NAME OF LICENSEE'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all bases that contain uber, lyft and via and others\n",
    "TLCbases[\"ALTERNATE NAME OF LICENSEE\"][TLCbases[\"ALTERNATE NAME OF LICENSEE\"].str.contains('uber')] = \"uber\"\n",
    "TLCbases[\"ALTERNATE NAME OF LICENSEE\"][TLCbases[\"ALTERNATE NAME OF LICENSEE\"].str.contains('lyft')] = \"lyft\"\n",
    "TLCbases[\"ALTERNATE NAME OF LICENSEE\"][TLCbases[\"ALTERNATE NAME OF LICENSEE\"].str.contains('via')] = \"via\"\n",
    "TLCbases[\"ALTERNATE NAME OF LICENSEE\"][~TLCbases[\"ALTERNATE NAME OF LICENSEE\"].str.contains('uber|lyft|via')] = \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TLCbases.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FHV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# FHV Taxi Processing Data Function\n",
    "def ProcessFHVData():\n",
    "    \"\"\" Need to fill in\"\"\"\n",
    "    # Create Blank Dataframe\n",
    "    df = pd.DataFrame(columns=['Dispatching_base_num', \n",
    "                               'Pickup_date', \n",
    "                               'locationID'])\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "    for yr in range(2015,2018):\n",
    "        # Define year\n",
    "        year = str(yr)\n",
    "\n",
    "        for mnth in range(1,13):\n",
    "            # Define month\n",
    "            month = ('{:02d}'.format(mnth))\n",
    "            \n",
    "            # Download Data and format\n",
    "            temp = pd.read_csv(\"Data/fhv_tripdata_\" + \n",
    "                               year + \"-\" + month + \".csv\")\n",
    "\n",
    "            # Fix data format when changed\n",
    "            if \"PUlocationID\" in temp.columns:\n",
    "                # Only select columns that exist in previous data\n",
    "                temp = temp[[\"Dispatching_base_num\",\n",
    "                             \"Pickup_DateTime\",\"PUlocationID\"]]\n",
    "                # Rename columns for merge\n",
    "                temp.rename(columns={\"PUlocationID\":\"locationID\",\n",
    "                                     \"Pickup_DateTime\":\"Pickup_date\"}, \n",
    "                            inplace=True)\n",
    "            \n",
    "            # Append to larger dataframe\n",
    "            df = pd.concat([df, temp]).reset_index(drop=True)\n",
    "            \n",
    "            # Provide Status Update\n",
    "            print(\"Completed \" + str(year) + \"-\" + str(month))\n",
    "            \n",
    "###############################################################################      \n",
    "    # Data Formatting and merging\n",
    "    # Merge with Taxi Base data set to determine actual bases\n",
    "    df = pd.merge(df,TLCbases,left_on='Dispatching_base_num',\n",
    "                  right_on='LICENSEE NUMBER')\n",
    "\n",
    "    # Merge Location IDs to get Borough and anme of zone\n",
    "    df = pd.merge(df,taxizones,left_on='locationID',right_on='LocationID')\n",
    "    \n",
    "    # Drop irrelevant columns\n",
    "    df = df[['Pickup_date','locationID','zone','borough',\n",
    "             'ALTERNATE NAME OF LICENSEE']]\n",
    "    \n",
    "    # Rename columns for merging\n",
    "    df.rename(columns={'Pickup_date':'pickup_date','locationID':'LocationID',\n",
    "                       'ALTERNATE NAME OF LICENSEE':'Base'},inplace=True)\n",
    "    \n",
    "    # Create Day and Hour Columns\n",
    "    df.pickup_date = pd.to_datetime(df.pickup_date)\n",
    "    df['date'] = df.pickup_date.dt.date\n",
    "    df['hour'] = df.pickup_date.dt.hour\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV = ProcessFHVData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHVgroup = FHV.groupby(('date','Base','zone'))['pickup_date'].count().reset_index()\n",
    "FHVgroup.rename(columns={'pickup_date':'COUNTS'},inplace=True)\n",
    "FHVgroup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pl.plot(FHVgroup['date'],FHVgroup['COUNTS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all taxi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data sets into one\n",
    "output = pd.concat([FHVgroup,GreenGroup,YellowGroup])\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('TaxiGrouped2015-2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YellowGroup2 = Yellow.groupby(('date','Base','zone'))['pickup_date'].count().reset_index()\n",
    "YellowGroup2.rename(columns={'pickup_date':'COUNTS'},inplace=True)\n",
    "\n",
    "GreenGroup2 = Green.groupby(('date','hour','Base','zone'))['pickup_date'].count().reset_index()\n",
    "GreenGroup2.rename(columns={'pickup_date':'COUNTS'},inplace=True)\n",
    "\n",
    "FHVgroup2 = FHV.groupby(('date','hour','Base','zone'))['pickup_date'].count().reset_index()\n",
    "FHVgroup2.rename(columns={'pickup_date':'COUNTS'},inplace=True)\n",
    "\n",
    "\n",
    "output2 = pd.concat([FHVgroup2,GreenGroup2,YellowGroup2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output.to_csv('TaxiGrouped2015-2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2.to_csv('TaxiGroupedHour2015-2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>zone</th>\n",
       "      <th>borough</th>\n",
       "      <th>Base</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-15 19:05:39</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-10 20:33:41</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-15 19:05:42</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-04 13:44:52</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-15 14:00:45</td>\n",
       "      <td>186.0</td>\n",
       "      <td>Penn Station/Madison Sq West</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>2015-01-15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_date  LocationID                          zone    borough  \\\n",
       "0 2015-01-15 19:05:39       186.0  Penn Station/Madison Sq West  Manhattan   \n",
       "1 2015-01-10 20:33:41       186.0  Penn Station/Madison Sq West  Manhattan   \n",
       "2 2015-01-15 19:05:42       186.0  Penn Station/Madison Sq West  Manhattan   \n",
       "3 2015-01-04 13:44:52       186.0  Penn Station/Madison Sq West  Manhattan   \n",
       "4 2015-01-15 14:00:45       186.0  Penn Station/Madison Sq West  Manhattan   \n",
       "\n",
       "     Base        date  hour  \n",
       "0  Yellow  2015-01-15    19  \n",
       "1  Yellow  2015-01-10    20  \n",
       "2  Yellow  2015-01-15    19  \n",
       "3  Yellow  2015-01-04    13  \n",
       "4  Yellow  2015-01-15    14  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yellow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
